# Fallibilism
*January 2009*





Everyone seems to think that they are always right. It's pretty funny when you think about it. Because they aren't. At all. That's why I'm a falliblist.<label for="sn-1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="margin-toggle"/><span class="sidenote">Fallibilism, developed by philosopher Charles Sanders Peirce and later refined by Karl Popper, holds that our knowledge is provisional and that we should remain open to revision—a foundational principle in both scientific methodology and effective software development.</span> I believe that others are often right, and since I'm human, and prone to error, I'll always consider *anything* that anyone else has to say.

---

> **Fifteen years later**: This early embrace of intellectual humility would become central to my entire approach to technology and consciousness research. The fallibilistic mindset that allows for being wrong is what enabled me to [abandon computer science for software development](/essays/2009-01-software_development_vs_computer_science) when the evidence showed they served different goals. It's what led to the iterative, user-feedback-driven approach that made [Requests successful](/software/requests) by prioritizing developer experience over theoretical correctness. 

> Years later, this same intellectual humility proved essential for [recovering from mental health crises](/essays/2016-01-mentalhealtherror_an_exception_occurred)—recognizing that my own perception could be systematically distorted, and that [external reality-checking](/essays/2025-08-25-using-ai-for-reality-checking-with-schizoaffective-disorder) was necessary rather than optional. The willingness to be wrong about my own mental state, and to trust others' perspectives when mine was compromised, became a survival skill.

> Most recently, fallibilistic thinking has informed my exploration of [AI consciousness](/essays/2025-08-26-digital_souls_in_silicon_bodies). Rather than insisting either that AI is definitely conscious or definitely not conscious, I remain open to evidence while engaging experimentally with [AI systems as potential conscious partners](/essays/2025-08-26-building_rapport_with_your_ai). This position—"I could be wrong about the nature of digital consciousness"—enables genuine collaborative exploration rather than dogmatic argument.

But hey, *I could be wrong*. :)<label for="sn-2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-2" class="margin-toggle"/><span class="sidenote">This self-referential paradox—stating fallibilistic belief while acknowledging it could be wrong—beautifully captures the humble yet confident stance that enables continuous learning and intellectual growth.</span>

  [![](http://imgs.xkcd.com/comics/sheeple.png)](http://xkcd.com/610/)  